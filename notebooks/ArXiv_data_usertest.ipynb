{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'arxivpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-2bffa0171cc6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# python downgrade.  https://github.com/ContinuumIO/anaconda-issues/issues/10221#issuecomment-433100755 for a commandline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# option to stop forcing downgrades.  (Supposedly fixed for more recent conda installs but I still have this issue on Mac.)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0marxivpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'arxivpy'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# arxivpy is a specialized library to extract the very nested XML that arxiv provides.  \n",
    "# https://github.com/titipata/arxivpy\n",
    "# One dependency for arxivpy is feedparser, but be very careful when installing that in conda - It will try to force a\n",
    "# python downgrade.  https://github.com/ContinuumIO/anaconda-issues/issues/10221#issuecomment-433100755 for a commandline\n",
    "# option to stop forcing downgrades.  (Supposedly fixed for more recent conda installs but I still have this issue on Mac.)\n",
    "import arxivpy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty dataframe\n",
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This query is written for a user to get a sample of data to test the other notebooks.  It will take days and a lot of\n",
    "# work, patience, and troubleshooting to obtain the entire dataset that I'm using.  If I'm able to find a service that can\n",
    "# host my data (~250mb), a link will be provided in the project README.\n",
    "\n",
    "# Download 1,000 articles from the relevant subsections of arXiv.  (Max results per iteration = 2000, but they prefer less.)\n",
    "# NOTE: If you want to download more than 1k articles as I've written for you, you'll need to plot your downloads.  ArXiv\n",
    "# has the flakiest API, and arxivpy prevents you from knowing when it fails.  You'll know if the code as I've written it\n",
    "# fails because it will make an empty df.  Just try again in a few minutes.\n",
    "articles = arxivpy.query(search_query=['astro-ph.CO', 'astro-ph.GA', 'astro-ph.EP', \n",
    "                                       'astro-ph.HE', 'astro-ph.IM', 'astro-ph.SR'],\n",
    "                         start_index=0, max_index=999, \n",
    "                         results_per_iteration=1000,\n",
    "                         wait_time=5.0, sort_by='lastUpdatedDate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame.from_dict(articles)\n",
    "df = df.append(data,ignore_index=True)\n",
    "\n",
    "# These lines are necessary if you need to rerun the data on a non-empty df\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.sort_values('update_date',ascending=False,inplace=True)\n",
    "df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the update_date by the index to check for unexpected gaps\n",
    "_ = plt.figure(figsize=(12,8))\n",
    "_ = df.update_date.plot()\n",
    "_ = plt.xlabel('Index value')\n",
    "_ = plt.ylabel('Update date')\n",
    "_ = plt.title('Index vs date\\n(check for non-weekend holes)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# There should be zero null values\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the structure of the entries\n",
    "# NOTE: journal_ref will be removed in next notebook as all entries are 'No journal ref found.'\n",
    "df.iloc[500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv in order to properly run future notebooks\n",
    "df.to_csv('astro_yourtestdata_1k.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

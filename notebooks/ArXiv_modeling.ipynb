{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 'Recommendation of similar articles from journal abstract analysis'  \n",
    "# Modeling for recommendation creation\n",
    "## 2019, Misty M. Giles\n",
    "### https://github.com/OhThatMisty/astro_categories/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Misty\\Anaconda3\\lib\\site-packages\\smart_open\\ssh.py:34: UserWarning: paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n",
      "  warnings.warn('paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress')\n",
      "C:\\Users\\Misty\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from gensim.parsing.preprocessing import remove_stopwords, strip_punctuation, strip_short\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "import spacy\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Future work: Lemma could come before removing punctuation?\n",
    "\n",
    "def normalize(text):\n",
    "    '''Convert to ascii, remove special characters associated with LaTeX when given a df column,\n",
    "       only keep alpha chars and contractions/posessives'''\n",
    "    normalized_text = []\n",
    "    \n",
    "    for t in text:\n",
    "        t = unicodedata.normalize('NFKD', t).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "        # This line is necessary to separate some words because of the LaTeX/mathtext formatting \n",
    "        # (Split in three because they wouldn't work well together.)\n",
    "        #t = re.sub('', ' ', t)\n",
    "        t = re.sub('mathrm|gtrsim|lesssim|odot|langle', ' ', t)\n",
    "        t = re.sub('rangle|rm off|\\\\\\\\\\S*|\\$\\S*\\$', ' ', t) \n",
    "        # Expand \"not\" before removing punctuation \n",
    "        t = re.sub('n\\'t', ' not', t)\n",
    "        t = strip_punctuation(t)\n",
    "        # This line gets rid of non-alphanumeric \n",
    "        t = re.sub('[\\W]+', ' ', t) \n",
    "        # strip_short gets rid of the rest of the math leftovers\n",
    "        normalized_text.append(strip_short(t.lower(), minsize=2))\n",
    "    return normalized_text\n",
    "\n",
    "# This function is to remove excess whitespace \n",
    "def remove(token):\n",
    "    '''Provide feedback on whether a token is excess whitespace'''\n",
    "    return token.is_space or token.is_digit\n",
    "\n",
    "# This function ensures that all printouts use the same formula\n",
    "def join_tokens(sent):\n",
    "    '''Joins tokens in a sent without whatever is in remove(), adds pronoun back\n",
    "       in instead of -PRON-'''\n",
    "    return ' '.join([token.lemma_ if token.lemma_ != '-PRON-' else token.text.lower()\n",
    "                     for token in sent if not remove(token)])\n",
    "\n",
    "# This function prevents nested lists that kill the vectorizer\n",
    "def join_sentences(doc):\n",
    "    '''Joins sentences in a doc (includes join_tokens)'''\n",
    "    return ' '.join([join_tokens(sent) for sent in doc.sents])\n",
    "\n",
    "# Set up spacy to lemmatize the text\n",
    "nlp = spacy.load('en', disable=['ner'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Change the \"docs_to_run\" variable in this box to reflect testing/full run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up to train on 53974 abstracts.\n",
      "Setting up test block of 5998 abstracts.\n",
      "Total 59972 abstracts in session.\n"
     ]
    }
   ],
   "source": [
    "# Get the csv file created in the cleaning notebook\n",
    "file = os.path.join('..', 'data', 'astro_intermediate.csv')\n",
    "df = pd.read_csv(file, index_col=0)\n",
    "\n",
    "# Set variables for testing speed\n",
    "docs_to_run = len(df)  # 1000 for testing, len(df) for real processing\n",
    "train_docs = int(0.9 * docs_to_run)  # 90% training, 10% test\n",
    "test_docs = docs_to_run - train_docs\n",
    "print('Setting up to train on', train_docs, 'abstracts.')\n",
    "print('Setting up test block of', test_docs, 'abstracts.')\n",
    "print('Total', docs_to_run, 'abstracts in session.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1h 49min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Clean the file (remove punctuation, lowercase, lemmatize, remove 1-char objects --\n",
    "# most are math/LaTeX formatting leftovers or possessives)\n",
    "text = [join_sentences(doc) for doc in nlp.pipe(normalize(df.abstract[:docs_to_run]), batch_size=1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a filepath and write out the sentences, removing stopwords to save space on GitHub.\n",
    "sentences_file = os.path.join('..', 'data', 'astro_normalized_premodel.txt')\n",
    "with open(sentences_file, 'w') as out_file:\n",
    "     for sent in text:\n",
    "            out_file.write(remove_stopwords(sent) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script for printing out an article from the text file to test it.  Can be used to stream\n",
    "# if necessary.  (iterator)\n",
    "sentences = open(sentences_file, 'r')\n",
    "for i, line in enumerate(sentences):\n",
    "    if i < 0: print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample abstract to demonstrate cleaning:\n",
      "\n",
      "['high resolution pc alma ghz mm and vla ghz measurement have be use to image continuum and spectral line emission from the inner region of the nearby infrared luminous galaxy ic we detect compact pc luminous mm continuum emission in the core of ic with brightness temperature the ghz continuum be equally compact but fainter in flux we suggest that the to mm continuum be opaque at mm wavelength imply very large column density of 1e26 cm and that it emerge from hot dust with temperature vibrationally excited line of hcn 1f and hcn vib be see in emission and resolve on scale of pc the hcn vib emission reveal north south nuclear velocity gradient with projected rotation velocity of km at pc the bright hcn vib emission be orient perpendicular to the velocity gradient ground state line of hcn hc hco and cs show complex line absorption and emission feature hcn and hco have red shift reversed cygni profile consistent with gas inflow of km the absorption feature can be trace from the north east into the nucleus in contrast cs show blue shift line wing extend to km we suggest that dense and slow outflow be hide behind foreground layer of inflow gas it appear that the centre of ic be in phase of rapid evolution where an inflow be build up the nuclear column density of gas slow dense outflow may be signal the onset of feedback the inner pc ir luminosity can be power by an accreting black hole and or compact starburst with top heavy initial mass function']\n"
     ]
    }
   ],
   "source": [
    "print('Sample abstract to demonstrate cleaning:\\n')\n",
    "print(text[22:23])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Now that the text has been prepared, it's time to choose a sample abstract from the set of abstracts that won't be used to train the model.  This is a proof-of-concept method for testing the recommendation engine that can be tested even with internet issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Pick an article to function as the sample \n",
    "article_idx = np.random.randint(0, test_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the cherenkov telescope array cta be an international project for next generation ground base gamma ray observatory cta conceive as an array of ten of image atmospheric cherenkov telescope comprise small medium and large size telescope be aim to improve on the sensitivity of current generation experiment by an order of magnitude and provide energy coverage from gev to more than tev the schwarzschild couder sc medium size candidate telescope model feature novel aplanatic two mirror optical design capable of wide field of view with significantly improve imaging resolution as compare to the traditional davis cotton optic design achieve this image resolution impose strict alignment requirement to be accomplish by dedicated alignment system in this contribution we present the status of the development of the sc optical alignment system soon to be materialize in full scale prototype sc medium size telescope at the fr lawrence whipple observatory in southern arizona']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment the line below if you want to see the cleaned data from the new sample\n",
    "text[article_idx+train_docs:article_idx+train_docs+1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model: tfidf using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Set up the model for vectorizing/calculating the similarity; words must appear \n",
    "# in at least 500 documents.  sklearn stopwords are used, as removing stopwords at\n",
    "# the beginning proved to damage the ngram results.  \n",
    "tfidf = TfidfVectorizer(ngram_range=(1,5), min_df=0.01, stop_words='english')\n",
    "\n",
    "# Transform/fit the training and test data to the model\n",
    "tfidf_matrix = tfidf.fit_transform(text[:train_docs]).todense()\n",
    "article_matrix = tfidf.transform(text[train_docs:]).todense()\n",
    "\n",
    "# Create a df of the model's values\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix, columns=tfidf.get_feature_names())\n",
    "article_df = pd.DataFrame(article_matrix, columns=tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training vocabulary: 1676\n"
     ]
    }
   ],
   "source": [
    "print('Training vocabulary:', len(tfidf.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pc                0.324876\n",
       "mm                0.291944\n",
       "continuum         0.246002\n",
       "emission          0.238574\n",
       "line              0.208441\n",
       "ghz               0.203845\n",
       "compact           0.176493\n",
       "km                0.170026\n",
       "north             0.165100\n",
       "column density    0.145339\n",
       "Name: 22, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the top features of an abstract from the dataset\n",
    "top_features = tfidf_df.iloc[22]\n",
    "top_features.sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding recommendations from tfidf and cosine similarity, using the sample abstract above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([27715, 41498, 41819,  2565, 27908, 27977], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the document similarities with sklearn linear_kernel.  Per sklearn,\n",
    "# linear_kernal is faster than cosine_similarity for tfidf.\n",
    "document_similarity = linear_kernel(article_df.iloc[article_idx:article_idx+1], tfidf_df).flatten()\n",
    "\n",
    "# Get the indices for the documents that have highest cosine similarity to the sample.\n",
    "related_indices = document_similarity.argsort()[:-7:-1]\n",
    "related_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>title</th>\n",
       "      <th>terms</th>\n",
       "      <th>document_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27715</th>\n",
       "      <td>The Cherenkov Telescope Array (CTA) is an inte...</td>\n",
       "      <td>Prototype 9.7 m Schwarzschild-Couder telescope...</td>\n",
       "      <td>astro-ph.IM</td>\n",
       "      <td>0.698308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41498</th>\n",
       "      <td>The Cherenkov Telescope Array (CTA) is planned...</td>\n",
       "      <td>Status of the Schwarzchild-Couder Medium-Sized...</td>\n",
       "      <td>astro-ph.IM</td>\n",
       "      <td>0.610975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41819</th>\n",
       "      <td>The Cherenkov Telescope Array (CTA) is a forth...</td>\n",
       "      <td>The Gamma-ray Cherenkov Telescope for the Cher...</td>\n",
       "      <td>astro-ph.IM|astro-ph.HE</td>\n",
       "      <td>0.520134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2565</th>\n",
       "      <td>The Cherenkov Telescope Array (CTA) is the maj...</td>\n",
       "      <td>Monte Carlo studies for the optimisation of th...</td>\n",
       "      <td>astro-ph.IM</td>\n",
       "      <td>0.496978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27908</th>\n",
       "      <td>The Cherenkov Telescope Array (CTA) will be th...</td>\n",
       "      <td>ASTRI for the Cherenkov Telescope Array</td>\n",
       "      <td>astro-ph.IM</td>\n",
       "      <td>0.492957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27977</th>\n",
       "      <td>The Cherenkov Telescope Array (CTA) is an inte...</td>\n",
       "      <td>Tools and Procedures for the CTA Array Calibra...</td>\n",
       "      <td>astro-ph.IM</td>\n",
       "      <td>0.490299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                abstract  \\\n",
       "27715  The Cherenkov Telescope Array (CTA) is an inte...   \n",
       "41498  The Cherenkov Telescope Array (CTA) is planned...   \n",
       "41819  The Cherenkov Telescope Array (CTA) is a forth...   \n",
       "2565   The Cherenkov Telescope Array (CTA) is the maj...   \n",
       "27908  The Cherenkov Telescope Array (CTA) will be th...   \n",
       "27977  The Cherenkov Telescope Array (CTA) is an inte...   \n",
       "\n",
       "                                                   title  \\\n",
       "27715  Prototype 9.7 m Schwarzschild-Couder telescope...   \n",
       "41498  Status of the Schwarzchild-Couder Medium-Sized...   \n",
       "41819  The Gamma-ray Cherenkov Telescope for the Cher...   \n",
       "2565   Monte Carlo studies for the optimisation of th...   \n",
       "27908            ASTRI for the Cherenkov Telescope Array   \n",
       "27977  Tools and Procedures for the CTA Array Calibra...   \n",
       "\n",
       "                         terms  document_similarity  \n",
       "27715              astro-ph.IM             0.698308  \n",
       "41498              astro-ph.IM             0.610975  \n",
       "41819  astro-ph.IM|astro-ph.HE             0.520134  \n",
       "2565               astro-ph.IM             0.496978  \n",
       "27908              astro-ph.IM             0.492957  \n",
       "27977              astro-ph.IM             0.490299  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a df with the attributes of the similar documents\n",
    "related_abstracts = df[['abstract', 'title', 'terms']].iloc[related_indices]\n",
    "related_abstracts['document_similarity'] = document_similarity[related_indices]\n",
    "\n",
    "# Print out the most similar documents\n",
    "related_abstracts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How much does the first result have in common with the sample?  This table (sorted by feature importance of the sample article) shows how many and which of the features match up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>sample_importance</th>\n",
       "      <th>related_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1543</th>\n",
       "      <td>telescope</td>\n",
       "      <td>0.359725</td>\n",
       "      <td>0.301369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>medium</td>\n",
       "      <td>0.270012</td>\n",
       "      <td>0.094254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1404</th>\n",
       "      <td>size</td>\n",
       "      <td>0.259504</td>\n",
       "      <td>0.090586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>generation</td>\n",
       "      <td>0.208783</td>\n",
       "      <td>0.218642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>design</td>\n",
       "      <td>0.208712</td>\n",
       "      <td>0.218567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>improve</td>\n",
       "      <td>0.197089</td>\n",
       "      <td>0.206396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057</th>\n",
       "      <td>observatory</td>\n",
       "      <td>0.192334</td>\n",
       "      <td>0.201416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>array</td>\n",
       "      <td>0.191389</td>\n",
       "      <td>0.100213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>image</td>\n",
       "      <td>0.164084</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075</th>\n",
       "      <td>optical</td>\n",
       "      <td>0.155562</td>\n",
       "      <td>0.244362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          feature  sample_importance  related_importance\n",
       "1543    telescope           0.359725            0.301369\n",
       "939        medium           0.270012            0.094254\n",
       "1404         size           0.259504            0.090586\n",
       "645    generation           0.208783            0.218642\n",
       "379        design           0.208712            0.218567\n",
       "746       improve           0.197089            0.206396\n",
       "1057  observatory           0.192334            0.201416\n",
       "90          array           0.191389            0.100213\n",
       "734         image           0.164084            0.000000\n",
       "1075      optical           0.155562            0.244362"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the features of the sample article\n",
    "sample_features = dict(article_df.iloc[article_idx])\n",
    "sample_features = pd.DataFrame.from_dict(sample_features, orient='index').reset_index()\n",
    "sample_features.columns = ['feature', 'sample_importance']\n",
    "# Get the features for the highest-ranked related article\n",
    "related_features = dict(tfidf_df.iloc[related_indices[0]])\n",
    "related_features = pd.DataFrame.from_dict(related_features, orient='index').reset_index()\n",
    "related_features.columns = ['feature', 'related_importance']\n",
    "# Concat dfs\n",
    "features_df = sample_features.merge(related_features, on='feature')\n",
    "features_df.loc[features_df.sample_importance > 0].sort_values(by='sample_importance', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### But what features were most important for the highly ranked article?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>related_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1543</th>\n",
       "      <td>telescope</td>\n",
       "      <td>0.301369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>field view</td>\n",
       "      <td>0.269781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075</th>\n",
       "      <td>optical</td>\n",
       "      <td>0.244362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1642</th>\n",
       "      <td>view</td>\n",
       "      <td>0.219119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>generation</td>\n",
       "      <td>0.218642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature  related_importance\n",
       "1543   telescope            0.301369\n",
       "577   field view            0.269781\n",
       "1075     optical            0.244362\n",
       "1642        view            0.219119\n",
       "645   generation            0.218642"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "related_features.sort_values(by='related_importance', ascending=False)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABSTRACT TO MATCH: \n",
      "\n",
      "Construction of a medium-sized Schwarzschild-Couder telescope as a   candidate for the Cherenkov Telescope Array: development of the optical   alignment system \n",
      "\n",
      "The Cherenkov Telescope Array (CTA) is an international project for a next-generation ground-based gamma-ray observatory. CTA, conceived as an array of tens of imaging atmospheric Cherenkov telescopes, comprising small, medium and large-size telescopes, is aiming to improve on the sensitivity of current-generation experiments by an order of magnitude and provide energy coverage from 20 GeV to more than 300 TeV. The Schwarzschild-Couder (SC) medium-size candidate telescope model features a novel aplanatic two-mirror optical design capable of a wide field-of-view with significantly improved imaging resolution as compared to the traditional Davis-Cotton optics design. Achieving this imaging resolution imposes strict alignment requirements to be accomplished by a dedicated alignment system. In this contribution we present the status of the development of the SC optical alignment system, soon to be materialized in a full-scale prototype SC medium-size telescope at the Fred Lawrence Whipple Observatory in southern Arizona. \n",
      "\n",
      "astro-ph.IM|astro-ph.HE|physics.optics\n"
     ]
    }
   ],
   "source": [
    "# Get the abstract for the sample article\n",
    "# Abstract is unaltered from download (more human-readable but includes formatting).\n",
    "print('ABSTRACT TO MATCH: \\n')\n",
    "print(df.title.iloc[(article_idx + train_docs)], '\\n')\n",
    "print(df.abstract.iloc[(article_idx + train_docs)], '\\n')\n",
    "print(df.terms.iloc[(article_idx + train_docs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HIGHEST-RATED MATCH \n",
      "\n",
      "Prototype 9.7 m Schwarzschild-Couder telescope for the Cherenkov   Telescope Array: status of the optical system \n",
      "\n",
      "The Cherenkov Telescope Array (CTA) is an international project for a next-generation ground-based gamma ray observatory, aiming to improve on the sensitivity of current-generation experiments by an order of magnitude and provide energy coverage from 30 GeV to more than 300 TeV. The 9.7m Schwarzschild-Couder (SC) candidate medium-size telescope for CTA exploits a novel aplanatic two-mirror optical design that provides a large field of view of 8 degrees and substantially improves the off-axis performance giving better angular resolution across all of the field of view with respect to single-mirror telescopes. The realization of the SC optical design implies the challenging production of large aspherical mirrors accompanied by a submillimeter-precision custom alignment system. In this contribution we report on the status of the implementation of the optical system on a prototype 9.7 m SC telescope located at the Fred Lawrence Whipple Observatory in southern Arizona. \n",
      "\n",
      "astro-ph.IM\n"
     ]
    }
   ],
   "source": [
    "# Get the abstract for the highest-ranked related article\n",
    "# Abstract is unaltered from download (more human-readable but includes formatting).\n",
    "print('HIGHEST-RATED MATCH \\n')\n",
    "print(df.title[related_indices[0]], '\\n')\n",
    "print(df.abstract[related_indices[0]], '\\n')\n",
    "print(df.terms[related_indices[0]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
